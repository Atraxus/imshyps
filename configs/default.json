{
    "metrics": [
        "accuracy"
    ],
    "params": {  
        "learning_rate": {
            "type": "float",
            "default": 0.001,
            "min": 0.0001,
            "max": 0.01
        },
        "batch_size": {
            "type": "int",
            "default": 32,
            "min": 32,
            "max": 128
        },
        "activation_function": {
            "type": "str",
            "default": "relu",
            "samples": [
                "relu",
                "sigmoid",
                "softmax",
                "softplus",
                "softsign",
                "tanh",
                "selu",
                "elu",
                "exponential"
            ]
        },
        "num_layers": {
            "type": "int",
            "default": 1,
            "min": 1,
            "max": 3
        },
        "num_neurons": {
            "type": "int",
            "default": 128,
            "min": 32,
            "max": 512
        }
    }
}