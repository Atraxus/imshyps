{
    "name": "default",
    "learning_rate": {
        "min": 0.0001,
        "max": 0.001
    },
    "batch_size": {
        "min": 32,
        "max": 128
    },
    "activation_functions": [
        "relu",
        "sigmoid",
        "softmax",
        "softplus",
        "softsign",
        "tanh",
        "selu",
        "elu",
        "exponential"
    ]
}